D:\Workplace-Pycharm\.venv\Scripts\python.exe D:\Workplace-Pycharm\QuantitativeTransaction\SRC\sq\test\test_gm\for159869\sq_test3_3_3.py
2025-02-15 16:58:25.194434: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-15 16:58:26.342570: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
----------------------------------------
python sdk version: 3.0.168
c sdk version: 3.7.4
----------------------------------------
[INFO]  Start...
[INFO]  ForSZTrainer train...
[INFO]  Model name: GBM_grid_1_AutoML_1_20250215_160840_model_5
Checking whether there is an H2O instance running at http://localhost:54321..... not found.
Attempting to start a local H2O server...
; OpenJDK 64-Bit Server VM 18.9 (build 11.0.2+9, mixed mode)
  Starting server from D:\Workplace-Pycharm\.venv\Lib\site-packages\h2o\backend\bin\h2o.jar
  Ice root: C:\Users\Andy\AppData\Local\Temp\tmpfay257nc
  JVM stdout: C:\Users\Andy\AppData\Local\Temp\tmpfay257nc\h2o_Andy_started_from_python.out
  JVM stderr: C:\Users\Andy\AppData\Local\Temp\tmpfay257nc\h2o_Andy_started_from_python.err
  Server is running at http://127.0.0.1:54321
Connecting to H2O server at http://127.0.0.1:54321 ... successful.
Warning: Your H2O cluster version is (7 months and 5 days) old.  There may be a newer version available.
Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html
--------------------------  -----------------------------
H2O_cluster_uptime:         03 secs
H2O_cluster_timezone:       Asia/Shanghai
H2O_data_parsing_timezone:  UTC
H2O_cluster_version:        3.46.0.4
H2O_cluster_version_age:    7 months and 5 days
H2O_cluster_name:           H2O_from_python_Andy_evmt8x
H2O_cluster_total_nodes:    1
H2O_cluster_free_memory:    3.844 Gb
H2O_cluster_total_cores:    16
H2O_cluster_allowed_cores:  16
H2O_cluster_status:         locked, healthy
H2O_connection_url:         http://127.0.0.1:54321
H2O_connection_proxy:       {"http": null, "https": null}
H2O_internal_security:      False
Python_version:             3.12.3 final
--------------------------  -----------------------------
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
response column levels:  [['0', '1']]
train shape: (507, 24)
test shape: (350, 24)
AutoML progress: |
16:58:58.49: AutoML: XGBoost is not available; skipping it.

███████████████████████████████████████████████████████████████| (done) 100%
********************
leaderboard:  model_id                                                      auc    logloss     aucpr    mean_per_class_error      rmse        mse
GBM_3_AutoML_1_20250215_165858                           0.980893   0.1802    0.979288               0.0717479  0.234771  0.0551176
GBM_4_AutoML_1_20250215_165858                           0.978751   0.186837  0.977854               0.0789064  0.238503  0.0568836
StackedEnsemble_BestOfFamily_1_AutoML_1_20250215_165858  0.978275   0.198962  0.978475               0.0784546  0.235722  0.055565
DRF_1_AutoML_1_20250215_165858                           0.978011   0.263607  0.97831                0.0676663  0.238526  0.0568948
StackedEnsemble_AllModels_1_AutoML_1_20250215_165858     0.977574   0.195831  0.977743               0.0760165  0.238051  0.0566682
GBM_grid_1_AutoML_1_20250215_165858_model_1              0.977271   0.19366   0.9763                 0.074373   0.241262  0.0582072
GBM_2_AutoML_1_20250215_165858                           0.977224   0.197339  0.975819               0.0787194  0.24569   0.0603634
XRT_1_AutoML_1_20250215_165858                           0.975728   0.271728  0.974801               0.0776601  0.246485  0.0607548
GBM_grid_1_AutoML_1_20250215_165858_model_2              0.975697   0.20802   0.9748                 0.0799657  0.247327  0.0611707
GBM_grid_1_AutoML_1_20250215_165858_model_5              0.975432   0.201893  0.972519               0.0770759  0.24583   0.0604323
[22 rows x 7 columns]

********************
leaderboard.head:  model_id                                                      auc    logloss     aucpr    mean_per_class_error      rmse        mse
GBM_3_AutoML_1_20250215_165858                           0.980893   0.1802    0.979288               0.0717479  0.234771  0.0551176
GBM_4_AutoML_1_20250215_165858                           0.978751   0.186837  0.977854               0.0789064  0.238503  0.0568836
StackedEnsemble_BestOfFamily_1_AutoML_1_20250215_165858  0.978275   0.198962  0.978475               0.0784546  0.235722  0.055565
DRF_1_AutoML_1_20250215_165858                           0.978011   0.263607  0.97831                0.0676663  0.238526  0.0568948
StackedEnsemble_AllModels_1_AutoML_1_20250215_165858     0.977574   0.195831  0.977743               0.0760165  0.238051  0.0566682
[5 rows x 7 columns]

********************
Best Model: Model Details
=============
H2OGradientBoostingEstimator : Gradient Boosting Machine
Model Key: GBM_3_AutoML_1_20250215_165858


Model Summary:
    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves
--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------
    92                 92                          29829                  8            8            8             12            33            21.1848

ModelMetricsBinomial: gbm
** Reported on train data. **

MSE: 0.0015388285526810584
RMSE: 0.03922790528031109
LogLoss: 0.024997666255577342
Mean Per-Class Error: 0.0
AUC: 1.0
AUCPR: 1.0
Gini: 1.0

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.7061474091179085
       0    1    Error    Rate
-----  ---  ---  -------  -----------
0      262  0    0        (0.0/262.0)
1      0    245  0        (0.0/245.0)
Total  262  245  0        (0.0/507.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.706147     1         192
max f2                       0.706147     1         192
max f0point5                 0.706147     1         192
max accuracy                 0.706147     1         192
max precision                0.999413     1         0
max recall                   0.706147     1         192
max specificity              0.999413     1         0
max absolute_mcc             0.706147     1         192
max min_per_class_accuracy   0.706147     1         192
max mean_per_class_accuracy  0.706147     1         192
max tns                      0.999413     262       0
max fns                      0.999413     244       0
max fps                      0.000933767  262       399
max tps                      0.706147     245       192
max tnr                      0.999413     1         0
max fnr                      0.999413     0.995918  0
max fpr                      0.000933767  1         399
max tpr                      0.706147     1         192

Gains/Lift Table: Avg response rate: 48.32 %, avg score: 48.30 %
group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov
-------  --------------------------  -----------------  -------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------
1        0.0118343                   0.998412           2.06939  2.06939            1                0.998856    1                           0.998856            0.0244898       0.0244898                  106.939  106.939            0.0244898
2        0.0216963                   0.997708           2.06939  2.06939            1                0.997872    1                           0.998409            0.0204082       0.044898                   106.939  106.939            0.044898
3        0.0315582                   0.997136           2.06939  2.06939            1                0.997361    1                           0.998081            0.0204082       0.0653061                  106.939  106.939            0.0653061
4        0.0414201                   0.996822           2.06939  2.06939            1                0.996968    1                           0.997816            0.0204082       0.0857143                  106.939  106.939            0.0857143
5        0.0512821                   0.996505           2.06939  2.06939            1                0.996651    1                           0.997592            0.0204082       0.106122                   106.939  106.939            0.106122
6        0.100592                    0.994989           2.06939  2.06939            1                0.995737    1                           0.996683            0.102041        0.208163                   106.939  106.939            0.208163
7        0.149901                    0.992871           2.06939  2.06939            1                0.993917    1                           0.995773            0.102041        0.310204                   106.939  106.939            0.310204
8        0.201183                    0.990261           2.06939  2.06939            1                0.991584    1                           0.994705            0.106122        0.416327                   106.939  106.939            0.416327
9        0.299803                    0.97801            2.06939  2.06939            1                0.985152    1                           0.991563            0.204082        0.620408                   106.939  106.939            0.620408
10       0.400394                    0.963148           2.06939  2.06939            1                0.971019    1                           0.986402            0.208163        0.828571                   106.939  106.939            0.828571
11       0.500986                    0.0864869          1.7042   1.99606            0.823529         0.778742    0.964567                    0.944706            0.171429        1                          70.4202  99.6063            0.965649
12       0.599606                    0.0322021          0        1.66776            0                0.0526451   0.805921                    0.797986            0               1                          -100     66.7763            0.774809
13       0.700197                    0.0172161          0        1.42817            0                0.0224411   0.690141                    0.686569            0               1                          -100     42.8169            0.580153
14       0.798817                    0.00940797         0        1.25185            0                0.0123573   0.604938                    0.603333            0               1                          -100     25.1852            0.389313
15       0.899408                    0.00589687         0        1.11184            0                0.00759478  0.537281                    0.536705            0               1                          -100     11.1842            0.194656
16       1                           0.000933767        0        1                  0                0.00298267  0.483235                    0.483017            0               1                          -100     0                  0

ModelMetricsBinomial: gbm
** Reported on cross-validation data. **

MSE: 0.05511761634870851
RMSE: 0.2347714129716574
LogLoss: 0.18019979143059953
Mean Per-Class Error: 0.07174793581554759
AUC: 0.980892662408475
AUCPR: 0.9792878449583136
Gini: 0.9617853248169499

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6046228853978979
       0    1    Error    Rate
-----  ---  ---  -------  ------------
0      249  13   0.0496   (13.0/262.0)
1      23   222  0.0939   (23.0/245.0)
Total  272  235  0.071    (36.0/507.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.604623     0.925     185
max f2                       0.111787     0.954438  243
max f0point5                 0.836218     0.944596  164
max accuracy                 0.626958     0.928994  183
max precision                0.999449     1         0
max recall                   0.022856     1         302
max specificity              0.999449     1         0
max absolute_mcc             0.626958     0.85857   183
max min_per_class_accuracy   0.496038     0.919847  197
max mean_per_class_accuracy  0.604623     0.928252  185
max tns                      0.999449     262       0
max fns                      0.999449     244       0
max fps                      0.000667766  262       399
max tps                      0.022856     245       302
max tnr                      0.999449     1         0
max fnr                      0.999449     0.995918  0
max fpr                      0.000667766  1         399
max tpr                      0.022856     1         302

Gains/Lift Table: Avg response rate: 48.32 %, avg score: 48.36 %
group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov
-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------
1        0.0118343                   0.998673           2.06939    2.06939            1                0.998925    1                           0.998925            0.0244898       0.0244898                  106.939   106.939            0.0244898
2        0.0216963                   0.998148           2.06939    2.06939            1                0.99841     1                           0.998691            0.0204082       0.044898                   106.939   106.939            0.044898
3        0.0315582                   0.997796           2.06939    2.06939            1                0.997942    1                           0.998457            0.0204082       0.0653061                  106.939   106.939            0.0653061
4        0.0414201                   0.997431           2.06939    2.06939            1                0.997596    1                           0.998252            0.0204082       0.0857143                  106.939   106.939            0.0857143
5        0.0512821                   0.997028           2.06939    2.06939            1                0.99715     1                           0.99804             0.0204082       0.106122                   106.939   106.939            0.106122
6        0.100592                    0.994184           2.06939    2.06939            1                0.995776    1                           0.99693             0.102041        0.208163                   106.939   106.939            0.208163
7        0.149901                    0.990051           2.06939    2.06939            1                0.992473    1                           0.995464            0.102041        0.310204                   106.939   106.939            0.310204
8        0.201183                    0.984133           1.9898     2.0491             0.961538         0.98685     0.990196                    0.993268            0.102041        0.412245                   98.9796   104.91             0.408428
9        0.299803                    0.959697           2.028      2.04216            0.98             0.973767    0.986842                    0.986853            0.2             0.612245                   102.8     104.216            0.604611
10       0.400394                    0.87454            1.98824    2.02861            0.960784         0.931512    0.980296                    0.97295             0.2             0.812245                   98.8235   102.861            0.796978
11       0.500986                    0.422155           1.17671    1.85756            0.568627         0.666692    0.897638                    0.911457            0.118367        0.930612                   17.6711   85.7561            0.831376
12       0.599606                    0.0717759          0.662204   1.66096            0.32             0.201731    0.802632                    0.794726            0.0653061       0.995918                   -33.7796  66.0956            0.766911
13       0.700197                    0.0228396          0.0405762  1.42817            0.0196078        0.0411099   0.690141                    0.68646             0.00408163      1                          -95.9424  42.8169            0.580153
14       0.798817                    0.0121391          0          1.25185            0                0.0171479   0.604938                    0.603829            0               1                          -100      25.1852            0.389313
15       0.899408                    0.00677133         0          1.11184            0                0.00908569  0.537281                    0.537311            0               1                          -100      11.1842            0.194656
16       1                           0.00064566         0          1                  0                0.00352561  0.483235                    0.483617            0               1                          -100      0                  0

Cross-Validation Metrics Summary:
                         mean         sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid
-----------------------  -----------  -----------  ------------  ------------  ------------  ------------  ------------
accuracy                 0.9408659    0.02411615   0.9313725     0.9313725     0.9108911     0.97029704    0.96039605
aic                      nan          0.0          nan           nan           nan           nan           nan
auc                      0.97988546   0.011826658  0.9707355     0.9727028     0.9705189     0.9944969     0.9909733
err                      0.059134148  0.02411615   0.068627454   0.068627454   0.089108914   0.02970297    0.03960396
err_count                6.0          2.4494898    7.0           7.0           9.0           3.0           4.0
f0point5                 0.9290321    0.03948086   0.944206      0.90909094    0.8695652     0.96311474    0.9591837
f1                       0.94068736   0.022851184  0.9263158     0.93457943    0.9142857     0.96907216    0.9591837
f2                       0.9537544    0.0257037    0.90909094    0.96153843    0.96385545    0.97510374    0.9591837
lift_top_group           2.070238     0.043147326  2.0816326     2.0           2.1041667     2.1041667     2.0612245
loglikelihood            nan          0.0          nan           nan           nan           nan           nan
---                      ---          ---          ---           ---           ---           ---           ---
mcc                      0.8856367    0.043427676  0.86372256    0.8669214     0.83612573    0.9406916     0.9207221
mean_per_class_accuracy  0.941531     0.023123546  0.93011165    0.9313725     0.9150943     0.9707154     0.96036106
mean_per_class_error     0.058468994  0.023123546  0.06988833    0.068627454   0.08490566    0.02928459    0.039638933
mse                      0.056308273  0.018382471  0.06940812    0.07256771    0.06685018    0.034295943   0.038419414
pr_auc                   0.97769636   0.014765202  0.973295      0.97032464    0.9592956     0.9942847     0.9912819
precision                0.9219703    0.05289015   0.95652175    0.89285713    0.84210527    0.9591837     0.9591837
r2                       0.7744554    0.07356678   0.7219399     0.70972914    0.73194236    0.8624792     0.84618664
recall                   0.96334034   0.039297394  0.8979592     0.98039216    1.0           0.9791667     0.9591837
rmse                     0.2345185    0.040455915  0.2634542     0.26938394    0.258554      0.18519163    0.19600871
specificity              0.91972166   0.06078846   0.9622642     0.88235295    0.8301887     0.9622642     0.96153843
[22 rows x 8 columns]


Scoring History:
    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error
--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------
    2025-02-15 16:59:03  0.755 sec   0                  0.499719         0.692585            0.5             0.483235           1                0.516765
    2025-02-15 16:59:03  0.772 sec   5                  0.378141         0.471085            0.981921        0.982244           2.06939          0.0571992
    2025-02-15 16:59:03  0.789 sec   10                 0.303428         0.349242            0.990933        0.990949           2.06939          0.0335306
    2025-02-15 16:59:03  0.805 sec   15                 0.261321         0.28217             0.99355         0.993711           2.06939          0.0295858
    2025-02-15 16:59:03  0.822 sec   20                 0.22486          0.227147            0.996121        0.995968           2.06939          0.0197239
    2025-02-15 16:59:03  0.839 sec   25                 0.198477         0.191399            0.997601        0.997539           2.06939          0.0157791
    2025-02-15 16:59:03  0.857 sec   30                 0.177228         0.16145             0.99831         0.998338           2.06939          0.0138067
    2025-02-15 16:59:03  0.873 sec   35                 0.153867         0.132883            0.999252        0.999236           2.06939          0.00788955
    2025-02-15 16:59:03  0.886 sec   40                 0.142016         0.117444            0.999517        0.999503           2.06939          0.00788955
    2025-02-15 16:59:03  0.902 sec   45                 0.128683         0.102487            0.999696        0.999685           2.06939          0.00591716
    2025-02-15 16:59:03  0.915 sec   50                 0.115962         0.0892049           0.999813        0.999803           2.06939          0.00394477
    2025-02-15 16:59:03  0.930 sec   55                 0.103128         0.0763944           0.999891        0.999884           2.06939          0.00394477
    2025-02-15 16:59:03  0.944 sec   60                 0.091658         0.0644974           0.999907        0.999902           2.06939          0.00394477
    2025-02-15 16:59:03  0.957 sec   65                 0.0816596        0.0562787           0.999984        0.999983           2.06939          0.00197239
    2025-02-15 16:59:03  0.972 sec   70                 0.0729752        0.0489871           0.999984        0.999983           2.06939          0.00197239
    2025-02-15 16:59:03  0.986 sec   75                 0.062004         0.0406139           1               1                  2.06939          0
    2025-02-15 16:59:03  1.002 sec   80                 0.0554234        0.0358966           1               1                  2.06939          0
    2025-02-15 16:59:03  1.017 sec   85                 0.04747          0.0307814           1               1                  2.06939          0
    2025-02-15 16:59:03  1.032 sec   90                 0.0411961        0.0261503           1               1                  2.06939          0
    2025-02-15 16:59:03  1.040 sec   92                 0.0392279        0.0249977           1               1                  2.06939          0

Variable Importances:
variable    relative_importance    scaled_importance     percentage
----------  ---------------------  --------------------  --------------------
ma15        67.0359115600586       1.0                   0.11544427236528759
close       61.9326057434082       0.9238720605435752    0.10665573778807196
ma95        53.84319305419922      0.8031992375603068    0.09272475154450338
ma80        47.06196975708008      0.7020411696037947    0.08104663199538553
ma5         41.02709197998047      0.6120166195282302    0.07065381331689959
ma25        37.8055419921875       0.5639595421674378    0.06510589898898059
ma20        37.036136627197266     0.5524820318735574    0.06378088616453846
ma90        30.33214569091797      0.4524760682002943    0.052235770456089216
ma100       25.06975555419922      0.37397500788422644   0.04317327266799721
ma55        21.75025749206543      0.32445680212133776   0.037456679434865935
---         ---                    ---                   ---
ma85        18.821990966796875     0.28077474489078796   0.03241383612246626
ma75        17.123401641845703     0.2554362466825645    0.029488651633988762
ma60        16.93555450439453      0.25263406001754274   0.029165155233413616
ma10        16.708942413330078     0.24925360190500664   0.028774900706350554
ma70        11.118200302124023     0.16585439122675377   0.019146939513760324
ma65        10.461634635925293     0.15606015331875572   0.018016250845098974
ma35        9.966102600097656      0.14866811486808618   0.0171628823448652
ma40        7.127446174621582      0.10632280532556022   0.012274358896645424
ma50        6.23834228515625       0.09305970695374545   0.010743210155802038
ma45        2.697888135910034      0.040245415824515955  0.004646102745899675
[22 rows x 4 columns]

gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%
********************
predictions.head:    predict        p0          p1
        0  0.987074  0.0129261
        0  0.992817  0.00718292
        0  0.99254   0.00746018
        0  0.993686  0.00631406
        0  0.992996  0.00700373
        0  0.990907  0.00909286
        0  0.991664  0.0083362
        0  0.988606  0.0113939
        0  0.988778  0.011222
        0  0.988947  0.0110529
[10 rows x 3 columns]

********************
metrics: ModelMetricsBinomial: gbm
** Reported on test data. **

MSE: 0.04853655978710045
RMSE: 0.22031014453969305
LogLoss: 0.15741998513651145
Mean Per-Class Error: 0.0625
AUC: 0.9863333333333334
AUCPR: 0.981671649504115
Gini: 0.9726666666666668

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4718323276805072
       0    1    Error    Rate
-----  ---  ---  -------  ------------
0      187  13   0.065    (13.0/200.0)
1      9    141  0.06     (9.0/150.0)
Total  196  154  0.0629   (22.0/350.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.471832     0.927632  151
max f2                       0.182648     0.966495  173
max f0point5                 0.849513     0.938462  122
max accuracy                 0.471832     0.937143  151
max precision                0.999354     1         0
max recall                   0.182648     1         173
max specificity              0.999354     1         0
max absolute_mcc             0.471832     0.872329  151
max min_per_class_accuracy   0.471832     0.935     151
max mean_per_class_accuracy  0.227483     0.938333  167
max tns                      0.999354     200       0
max fns                      0.999354     149       0
max fps                      0.00105598   200       344
max tps                      0.182648     150       173
max tnr                      0.999354     1         0
max fnr                      0.999354     0.993333  0
max fpr                      0.00105598   1         344
max tpr                      0.182648     1         173

Gains/Lift Table: Avg response rate: 42.86 %, avg score: 43.76 %
group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov
-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------
1        0.0114286                   0.99895            2.33333    2.33333            1                0.999226    1                           0.999226            0.0266667       0.0266667                  133.333   133.333            0.0266667
2        0.02                        0.998501           2.33333    2.33333            1                0.998834    1                           0.999058            0.02            0.0466667                  133.333   133.333            0.0466667
3        0.0314286                   0.997592           2.33333    2.33333            1                0.997987    1                           0.998669            0.0266667       0.0733333                  133.333   133.333            0.0733333
4        0.04                        0.997177           2.33333    2.33333            1                0.997434    1                           0.998404            0.02            0.0933333                  133.333   133.333            0.0933333
5        0.0514286                   0.996849           2.33333    2.33333            1                0.997019    1                           0.998096            0.0266667       0.12                       133.333   133.333            0.12
6        0.1                         0.993139           2.33333    2.33333            1                0.994967    1                           0.996576            0.113333        0.233333                   133.333   133.333            0.233333
7        0.154286                    0.989879           2.33333    2.33333            1                0.992002    1                           0.994967            0.126667        0.36                       133.333   133.333            0.36
8        0.202857                    0.983775           2.33333    2.33333            1                0.986964    1                           0.993051            0.113333        0.473333                   133.333   133.333            0.473333
9        0.3                         0.940396           2.26471    2.31111            0.970588         0.967028    0.990476                    0.984624            0.22            0.693333                   126.471   131.111            0.688333
10       0.4                         0.680438           1.8        2.18333            0.771429         0.84569     0.935714                    0.949891            0.18            0.873333                   80        118.333            0.828333
11       0.5                         0.186007           1.2        1.98667            0.514286         0.421076    0.851429                    0.844128            0.12            0.993333                   20        98.6667            0.863333
12       0.6                         0.0454322          0.0666667  1.66667            0.0285714        0.0988769   0.714286                    0.719919            0.00666667      1                          -93.3333  66.6667            0.7
13       0.7                         0.0200821          0          1.42857            0                0.0315541   0.612245                    0.621582            0               1                          -100      42.8571            0.525
14       0.8                         0.0109889          0          1.25               0                0.0147009   0.535714                    0.545721            0               1                          -100      25                 0.35
15       0.9                         0.00538086         0          1.11111            0                0.00770061  0.47619                     0.485941            0               1                          -100      11.1111            0.175
16       1                           0.00105598         0          1                  0                0.00293068  0.428571                    0.43764             0               1                          -100      0                  0
********************
Accuracy: [[0.4718323276805072, 0.9371428571428572]]
[INFO]  getting best model finished!, time elapsed: 326.20748257637024 seconds