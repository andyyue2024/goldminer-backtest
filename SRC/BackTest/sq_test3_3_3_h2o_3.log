D:\Workplace-Pycharm\.venv\Scripts\python.exe D:\Workplace-Pycharm\QuantitativeTransaction\SRC\sq\test\test_gm\for159869\sq_test3_3_3.py
2025-02-15 16:37:40.024618: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-15 16:37:41.158189: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
----------------------------------------
python sdk version: 3.0.168
c sdk version: 3.7.4
----------------------------------------
[INFO]  Start...
[INFO]  ForSZTrainer train...
[INFO]  Model name: GBM_grid_1_AutoML_1_20250215_160840_model_5
Checking whether there is an H2O instance running at http://localhost:54321..... not found.
Attempting to start a local H2O server...
; OpenJDK 64-Bit Server VM 18.9 (build 11.0.2+9, mixed mode)
  Starting server from D:\Workplace-Pycharm\.venv\Lib\site-packages\h2o\backend\bin\h2o.jar
  Ice root: C:\Users\Andy\AppData\Local\Temp\tmpl3xwjfyd
  JVM stdout: C:\Users\Andy\AppData\Local\Temp\tmpl3xwjfyd\h2o_Andy_started_from_python.out
  JVM stderr: C:\Users\Andy\AppData\Local\Temp\tmpl3xwjfyd\h2o_Andy_started_from_python.err
  Server is running at http://127.0.0.1:54321
Connecting to H2O server at http://127.0.0.1:54321 ... successful.
Warning: Your H2O cluster version is (7 months and 5 days) old.  There may be a newer version available.
Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html
--------------------------  -----------------------------
H2O_cluster_uptime:         03 secs
H2O_cluster_timezone:       Asia/Shanghai
H2O_data_parsing_timezone:  UTC
H2O_cluster_version:        3.46.0.4
H2O_cluster_version_age:    7 months and 5 days
H2O_cluster_name:           H2O_from_python_Andy_b8q5os
H2O_cluster_total_nodes:    1
H2O_cluster_free_memory:    3.844 Gb
H2O_cluster_total_cores:    16
H2O_cluster_allowed_cores:  16
H2O_cluster_status:         locked, healthy
H2O_connection_url:         http://127.0.0.1:54321
H2O_connection_proxy:       {"http": null, "https": null}
H2O_internal_security:      False
Python_version:             3.12.3 final
--------------------------  -----------------------------
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
response column levels:  [['0', '1']]
train shape: (809, 24)
test shape: (48, 24)
AutoML progress: |
16:38:12.935: AutoML: XGBoost is not available; skipping it.

███████████████████████████████████████████████████████████████| (done) 100%
********************
leaderboard:  model_id                                                      auc    logloss     aucpr    mean_per_class_error      rmse        mse
GBM_grid_1_AutoML_1_20250215_163812_model_5              0.995652  0.0873112  0.994868               0.0373046  0.166579  0.0277487
StackedEnsemble_BestOfFamily_1_AutoML_1_20250215_163812  0.995529  0.086064   0.994778               0.0399166  0.167028  0.0278983
StackedEnsemble_AllModels_1_AutoML_1_20250215_163812     0.995245  0.0873227  0.994448               0.0392043  0.168804  0.0284948
GBM_4_AutoML_1_20250215_163812                           0.994862  0.0962294  0.993959               0.0367095  0.17291   0.0298978
GBM_grid_1_AutoML_1_20250215_163812_model_1              0.994616  0.0956289  0.993686               0.0427074  0.172865  0.0298824
GBM_3_AutoML_1_20250215_163812                           0.994412  0.100309   0.993503               0.0431238  0.177347  0.031452
XRT_1_AutoML_1_20250215_163812                           0.993987  0.130917   0.993011               0.0438361  0.189233  0.0358092
GBM_2_AutoML_1_20250215_163812                           0.993752  0.106437   0.992633               0.0450265  0.185013  0.0342299
GBM_grid_1_AutoML_1_20250215_163812_model_3              0.993626  0.108714   0.99253                0.0433026  0.180937  0.0327381
GBM_5_AutoML_1_20250215_163812                           0.993512  0.113358   0.992454               0.0472807  0.188564  0.0355564
[22 rows x 7 columns]

********************
leaderboard.head:  model_id                                                      auc    logloss     aucpr    mean_per_class_error      rmse        mse
GBM_grid_1_AutoML_1_20250215_163812_model_5              0.995652  0.0873112  0.994868               0.0373046  0.166579  0.0277487
StackedEnsemble_BestOfFamily_1_AutoML_1_20250215_163812  0.995529  0.086064   0.994778               0.0399166  0.167028  0.0278983
StackedEnsemble_AllModels_1_AutoML_1_20250215_163812     0.995245  0.0873227  0.994448               0.0392043  0.168804  0.0284948
GBM_4_AutoML_1_20250215_163812                           0.994862  0.0962294  0.993959               0.0367095  0.17291   0.0298978
GBM_grid_1_AutoML_1_20250215_163812_model_1              0.994616  0.0956289  0.993686               0.0427074  0.172865  0.0298824
[5 rows x 7 columns]

********************
Best Model: Model Details
=============
H2OGradientBoostingEstimator : Gradient Boosting Machine
Model Key: GBM_grid_1_AutoML_1_20250215_163812_model_5


Model Summary:
    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves
--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------
    122                122                         64828                  9            17           15.1557       28            41            37.6721

ModelMetricsBinomial: gbm
** Reported on train data. **

MSE: 1.4027090132473879e-05
RMSE: 0.003745275708472459
LogLoss: 0.0017979612326319437
Mean Per-Class Error: 0.0
AUC: 1.0
AUCPR: 1.0
Gini: 1.0

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9652392656089809
       0    1    Error    Rate
-----  ---  ---  -------  -----------
0      443  0    0        (0.0/443.0)
1      0    366  0        (0.0/366.0)
Total  443  366  0        (0.0/809.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.965239     1         193
max f2                       0.965239     1         193
max f0point5                 0.965239     1         193
max accuracy                 0.965239     1         193
max precision                0.999993     1         0
max recall                   0.965239     1         193
max specificity              0.999993     1         0
max absolute_mcc             0.965239     1         193
max min_per_class_accuracy   0.965239     1         193
max mean_per_class_accuracy  0.965239     1         193
max tns                      0.999993     443       0
max fns                      0.999993     364       0
max fps                      6.29068e-06  443       399
max tps                      0.965239     366       193
max tnr                      0.999993     1         0
max fnr                      0.999993     0.994536  0
max fpr                      6.29068e-06  1         399
max tpr                      0.965239     1         193

Gains/Lift Table: Avg response rate: 45.24 %, avg score: 45.24 %
group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov
-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------
1        0.0111248                   0.999986           2.21038  2.21038            1                0.999989     1                           0.999989            0.0245902       0.0245902                  121.038  121.038            0.0245902
2        0.0210136                   0.99997            2.21038  2.21038            1                0.999979     1                           0.999985            0.0218579       0.0464481                  121.038  121.038            0.0464481
3        0.0309023                   0.99996            2.21038  2.21038            1                0.999965     1                           0.999978            0.0218579       0.068306                   121.038  121.038            0.068306
4        0.0407911                   0.999947           2.21038  2.21038            1                0.999954     1                           0.999972            0.0218579       0.0901639                  121.038  121.038            0.0901639
5        0.0506799                   0.999928           2.21038  2.21038            1                0.999938     1                           0.999966            0.0218579       0.112022                   121.038  121.038            0.112022
6        0.100124                    0.99983            2.21038  2.21038            1                0.999888     1                           0.999928            0.10929         0.221311                   121.038  121.038            0.221311
7        0.150803                    0.999706           2.21038  2.21038            1                0.999777     1                           0.999877            0.112022        0.333333                   121.038  121.038            0.333333
8        0.200247                    0.999506           2.21038  2.21038            1                0.99961      1                           0.999811            0.10929         0.442623                   121.038  121.038            0.442623
9        0.300371                    0.998525           2.21038  2.21038            1                0.999099     1                           0.999574            0.221311        0.663934                   121.038  121.038            0.663934
10       0.400494                    0.994818           2.21038  2.21038            1                0.997219     1                           0.998985            0.221311        0.885246                   121.038  121.038            0.885246
11       0.500618                    0.00509999         1.14612  1.99753            0.518519         0.518312     0.903704                    0.90285             0.114754        1                          14.6124  99.7531            0.911964
12       0.599506                    0.00143084         0        1.66804            0                0.00249347   0.754639                    0.754338            0               1                          -100     66.8041            0.731377
13       0.699629                    0.000640476        0        1.42933            0                0.000962851  0.646643                    0.646523            0               1                          -100     42.9329            0.548533
14       0.799753                    0.00035117         0        1.25039            0                0.000479726  0.565688                    0.565643            0               1                          -100     25.0386            0.365688
15       0.899876                    0.000116713        0        1.11126            0                0.00023852   0.502747                    0.502734            0               1                          -100     11.1264            0.182844
16       1                           5.01257e-06        0        1                  0                4.14735e-05  0.45241                     0.452402            0               1                          -100     0                  0

ModelMetricsBinomial: gbm
** Reported on cross-validation data. **

MSE: 0.027748729365391647
RMSE: 0.1665794986347109
LogLoss: 0.08731119215425528
Mean Per-Class Error: 0.03730464172495035
AUC: 0.9956518521259667
AUCPR: 0.9948684890698192
Gini: 0.9913037042519335

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.173501792366796
       0    1    Error    Rate
-----  ---  ---  -------  ------------
0      416  27   0.0609   (27.0/443.0)
1      5    361  0.0137   (5.0/366.0)
Total  421  388  0.0396   (32.0/809.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.173502     0.95756   215
max f2                       0.141295     0.976857  220
max f0point5                 0.788752     0.971731  160
max accuracy                 0.586577     0.960445  185
max precision                0.999993     1         0
max recall                   0.0307413    1         252
max specificity              0.999993     1         0
max absolute_mcc             0.173502     0.921957  215
max min_per_class_accuracy   0.392327     0.959368  197
max mean_per_class_accuracy  0.173502     0.962695  215
max tns                      0.999993     443       0
max fns                      0.999993     354       0
max fps                      3.7664e-06   443       399
max tps                      0.0307413    366       252
max tnr                      0.999993     1         0
max fnr                      0.999993     0.967213  0
max fpr                      3.7664e-06   1         399
max tpr                      0.0307413    1         252

Gains/Lift Table: Avg response rate: 45.24 %, avg score: 44.78 %
group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov
-------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------
1        0.0111248                   0.99999            2.21038    2.21038            1                0.999995     1                           0.999995            0.0245902       0.0245902                  121.038  121.038            0.0245902
2        0.0210136                   0.999979           2.21038    2.21038            1                0.999985     1                           0.99999             0.0218579       0.0464481                  121.038  121.038            0.0464481
3        0.0309023                   0.999956           2.21038    2.21038            1                0.999966     1                           0.999982            0.0218579       0.068306                   121.038  121.038            0.068306
4        0.0407911                   0.999938           2.21038    2.21038            1                0.999946     1                           0.999973            0.0218579       0.0901639                  121.038  121.038            0.0901639
5        0.0506799                   0.999917           2.21038    2.21038            1                0.999924     1                           0.999964            0.0218579       0.112022                   121.038  121.038            0.112022
6        0.100124                    0.999611           2.21038    2.21038            1                0.999799     1                           0.999882            0.10929         0.221311                   121.038  121.038            0.221311
7        0.150803                    0.999179           2.21038    2.21038            1                0.999378     1                           0.999713            0.112022        0.333333                   121.038  121.038            0.333333
8        0.200247                    0.99848            2.21038    2.21038            1                0.998845     1                           0.999499            0.10929         0.442623                   121.038  121.038            0.442623
9        0.300371                    0.991392           2.21038    2.21038            1                0.996192     1                           0.998396            0.221311        0.663934                   121.038  121.038            0.663934
10       0.400494                    0.891524           2.12852    2.18992            0.962963         0.97282      0.990741                    0.992002            0.213115        0.877049                   112.852  118.992            0.870277
11       0.500618                    0.0879664          1.17341    1.98662            0.530864         0.473211     0.898765                    0.888244            0.117486        0.994536                   17.3413  98.6615            0.901985
12       0.599506                    0.00616052         0.0552596  1.66804            0.025            0.0259679    0.754639                    0.746013            0.00546448      1                          -94.474  66.8041            0.731377
13       0.699629                    0.00217682         0          1.42933            0                0.00374303   0.646643                    0.639787            0               1                          -100     42.9329            0.548533
14       0.799753                    0.000630596        0          1.25039            0                0.0012473    0.565688                    0.559846            0               1                          -100     25.0386            0.365688
15       0.899876                    0.000154776        0          1.11126            0                0.000333547  0.502747                    0.497593            0               1                          -100     11.1264            0.182844
16       1                           1.29e-06           0          1                  0                5.4844e-05   0.45241                     0.447777            0               1                          -100     0                  0

Cross-Validation Metrics Summary:
                         mean         sd            cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid
-----------------------  -----------  ------------  ------------  ------------  ------------  ------------  ------------
accuracy                 0.96789354   0.020179583   0.97530866    0.9382716     0.9691358     0.962963      0.99378884
aic                      nan          0.0           nan           nan           nan           nan           nan
auc                      0.9953891    0.0041219364  0.9976625     0.9884828     0.99511075    0.99662834    0.99906105
err                      0.032106433  0.020179583   0.024691358   0.061728396   0.030864198   0.037037037   0.0062111802
err_count                5.2          3.2710855     4.0           10.0          5.0           6.0           1.0
f0point5                 0.9586835    0.030158963   0.98784196    0.9196891     0.95717883    0.9398496     0.9888579
f1                       0.9654116    0.021094868   0.9701493     0.93421054    0.9681529     0.96153843    0.993007
f2                       0.9726203    0.020707455   0.95307916    0.9491979     0.97938144    0.984252      0.997191
lift_top_group           2.2137034    0.09544238    2.347826      2.1891892     2.1038961     2.16          2.2676055
loglikelihood            nan          0.0           nan           nan           nan           nan           nan
---                      ---          ---           ---           ---           ---           ---           ---
mcc                      0.93648756   0.039926987   0.9503591     0.87722397    0.9388789     0.9284767     0.987499
mean_per_class_accuracy  0.968182     0.019395314   0.9710145     0.939957      0.9699771     0.9655172     0.99444443
mean_per_class_error     0.031817947  0.019395314   0.028985508   0.060042996   0.03002292    0.03448276    0.0055555557
mse                      0.028236514  0.013764215   0.021778604   0.048041213   0.03508947    0.024174262   0.012099017
pr_auc                   0.99471366   0.0045168847  0.99694294    0.98710287    0.99455154    0.9961964     0.99877447
precision                0.9544587    0.038287487   1.0           0.9102564     0.95          0.9259259     0.9861111
r2                       0.8860617    0.055154823   0.9109307     0.8063892     0.859299      0.90276945    0.9509204
recall                   0.9777003    0.025915489   0.942029      0.9594595     0.987013      1.0           1.0
rmse                     0.16391139   0.041375883   0.14757575    0.21918306    0.18732183    0.15548074    0.10999554
specificity              0.9586638    0.03492246    1.0           0.92045456    0.9529412     0.9310345     0.98888886
[22 rows x 8 columns]


Scoring History:
     timestamp            duration    number_of_trees    training_rmse          training_logloss       training_auc        training_pr_auc     training_lift      training_classification_error
---  -------------------  ----------  -----------------  ---------------------  ---------------------  ------------------  ------------------  -----------------  -------------------------------
     2025-02-15 16:38:38  8.323 sec   0.0                0.4977300758159923     0.6886107734801309     0.5                 0.4524103831891224  1.0                0.5475896168108776
     2025-02-15 16:38:38  8.385 sec   5.0                0.3652560890240033     0.4496969420341685     0.9852841406702932  0.9818970717081515  2.210382513661202  0.05562422744128554
     2025-02-15 16:38:38  8.414 sec   10.0               0.2820742317486697     0.3172285570857507     0.9940729502029136  0.9927994581913572  2.210382513661202  0.037082818294190356
     2025-02-15 16:38:39  8.449 sec   15.0               0.2260350380808978     0.23333107656656554    0.9973633571402138  0.9968210066551046  2.210382513661202  0.024721878862793572
     2025-02-15 16:38:39  8.483 sec   20.0               0.1823163555952976     0.1733280422979865     0.9994880903921352  0.9993902480629987  2.210382513661202  0.012360939431396786
     2025-02-15 16:38:39  8.514 sec   25.0               0.14740447290864894    0.1305730870032661     0.9999814972430892  0.9999777565092492  2.210382513661202  0.0012360939431396785
     2025-02-15 16:38:39  8.545 sec   30.0               0.12143226158060853    0.10008280630188893    1.0                 1.0                 2.210382513661202  0.0
     2025-02-15 16:38:39  8.573 sec   35.0               0.10007251282271766    0.07766964921206868    1.0                 1.0                 2.210382513661202  0.0
     2025-02-15 16:38:39  8.603 sec   40.0               0.08182441429421643    0.06050582345799431    1.0                 1.0                 2.210382513661202  0.0
     2025-02-15 16:38:39  8.633 sec   45.0               0.06659318832968905    0.04705728133133596    1.0                 0.9999999999999999  2.210382513661202  0.0
---  ---                  ---         ---                ---                    ---                    ---                 ---                 ---                ---
     2025-02-15 16:38:39  8.853 sec   80.0               0.017271204952505847   0.009847925563095867   1.0                 1.0                 2.210382513661202  0.0
     2025-02-15 16:38:39  8.880 sec   85.0               0.014224458317812138   0.007943685417757744   1.0                 1.0                 2.210382513661202  0.0
     2025-02-15 16:38:39  8.907 sec   90.0               0.01158690900946381    0.006369620030757643   1.0                 1.0                 2.210382513661202  0.0
     2025-02-15 16:38:39  8.937 sec   95.0               0.009667058430724957   0.005193145180633045   1.0                 1.0                 2.210382513661202  0.0
     2025-02-15 16:38:39  8.964 sec   100.0              0.007988475939607696   0.004244149132443815   1.0                 1.0                 2.210382513661202  0.0
     2025-02-15 16:38:39  8.991 sec   105.0              0.006735968872603684   0.0034981977407216366  1.0                 1.0                 2.210382513661202  0.0
     2025-02-15 16:38:39  9.021 sec   110.0              0.00563621633495593    0.0028649494923940286  1.0                 1.0                 2.210382513661202  0.0
     2025-02-15 16:38:39  9.048 sec   115.0              0.004732298871739318   0.002337732170051001   1.0                 1.0                 2.210382513661202  0.0
     2025-02-15 16:38:39  9.077 sec   120.0              0.0039963496850051565  0.001937476897686072   1.0                 1.0                 2.210382513661202  0.0
     2025-02-15 16:38:39  9.092 sec   122.0              0.003745275708472459   0.0017979612326319437  1.0                 1.0                 2.210382513661202  0.0
[26 rows x 10 columns]


Variable Importances:
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  --------------------
ma95        176.27365112304688     1.0                  0.1814567141037575
ma100       70.70455169677734      0.4011067521794418   0.07278351325531168
ma75        65.29064178466797      0.37039365423418946  0.06721041542221932
ma80        64.91116333007812      0.36824087387154214  0.06681977897142624
close       54.354427337646484     0.30835253590852707  0.055952637951522215
ma55        54.02657699584961      0.3064926417059158   0.05561514766093575
ma5         53.48540115356445      0.30342255245073046  0.05505805935268456
ma90        51.19447326660156      0.29042612404315343  0.0526997701587609
ma70        50.7502326965332       0.2879059483547389   0.052242467359377036
ma85        43.235069274902344     0.2452724442901698   0.04450633180109113
---         ---                    ---                  ---
ma65        34.853275299072266     0.19772254717038296  0.03587808371376289
ma15        31.55936622619629      0.17903620890093463  0.032487322172757495
ma40        30.764877319335938     0.1745290752380268   0.03166947250825981
ma30        25.778018951416016     0.14623863967860862  0.02653598303108369
ma25        19.76021385192871      0.1120996457839022   0.020341233376142027
ma20        18.113046646118164     0.10275527017633763  0.01864563368304206
ma3         15.7666597366333       0.08944422286702094  0.016230254777013786
ma10        11.211523056030273     0.06360294340419675  0.011541181117452799
ma60        9.897844314575195      0.05615044705499438  0.010188875618056288
ma50        8.552956581115723      0.04852090216901094  0.008804443472938605
[22 rows x 4 columns]

gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%
********************
predictions.head:    predict           p0           p1
        0  0.999908     9.18683e-05
        1  0.00401047   0.99599
        1  0.000582905  0.999417
        1  0.000187234  0.999813
        0  0.999043     0.000956983
        0  0.243579     0.756421
        0  0.726809     0.273191
        0  0.51473      0.48527
        1  0.000224748  0.999775
        0  0.999676     0.000323677
[10 rows x 3 columns]

********************
metrics: ModelMetricsBinomial: gbm
** Reported on test data. **

MSE: 0.07610200285158344
RMSE: 0.27586591462444837
LogLoss: 0.22147241561418415
Mean Per-Class Error: 0.08711433756805807
AUC: 0.9764065335753177
AUCPR: 0.9855456021734131
Gini: 0.9528130671506354

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2731910014439181
       0    1    Error    Rate
-----  ---  ---  -------  ----------
0      17   2    0.1053   (2.0/19.0)
1      2    27   0.069    (2.0/29.0)
Total  19   29   0.0833   (4.0/48.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.273191     0.931034  28
max f2                       0.0527616    0.966667  33
max f0point5                 0.756421     0.968992  24
max accuracy                 0.756421     0.916667  24
max precision                0.999889     1         0
max recall                   0.0527616    1         33
max specificity              0.999889     1         0
max absolute_mcc             0.756421     0.843886  24
max min_per_class_accuracy   0.48527      0.894737  27
max mean_per_class_accuracy  0.756421     0.931034  24
max tns                      0.999889     19        0
max fns                      0.999889     28        0
max fps                      1.448e-05    19        47
max tps                      0.0527616    29        33
max tnr                      0.999889     1         0
max fnr                      0.999889     0.965517  0
max fpr                      1.448e-05    1         47
max tpr                      0.0527616    1         33

Gains/Lift Table: Avg response rate: 60.42 %, avg score: 56.88 %
group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain       cumulative_gain    kolmogorov_smirnov
-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  ---------  -----------------  --------------------
1        0.0208333                   0.999888           1.65517   1.65517            1                0.999889     1                           0.999889            0.0344828       0.0344828                  65.5172    65.5172            0.0344828
2        0.0208333                   0.999887           0         1.65517            0                0            1                           0.999889            0               0.0344828                  -100       65.5172            0.0344828
3        0.0416667                   0.999879           1.65517   1.65517            1                0.999887     1                           0.999888            0.0344828       0.0689655                  65.5172    65.5172            0.0689655
4        0.0416667                   0.99987            0         1.65517            0                0            1                           0.999888            0               0.0689655                  -100       65.5172            0.0689655
5        0.0625                      0.999868           1.65517   1.65517            1                0.999868     1                           0.999881            0.0344828       0.103448                   65.5172    65.5172            0.103448
6        0.104167                    0.999787           1.65517   1.65517            1                0.99984      1                           0.999865            0.0689655       0.172414                   65.5172    65.5172            0.172414
7        0.166667                    0.999441           1.65517   1.65517            1                0.999648     1                           0.999784            0.103448        0.275862                   65.5172    65.5172            0.275862
8        0.208333                    0.999103           1.65517   1.65517            1                0.999283     1                           0.999683            0.0689655       0.344828                   65.5172    65.5172            0.344828
9        0.3125                      0.997476           1.65517   1.65517            1                0.998282     1                           0.999216            0.172414        0.517241                   65.5172    65.5172            0.517241
10       0.395833                    0.993575           1.65517   1.65517            1                0.996468     1                           0.998638            0.137931        0.655172                   65.5172    65.5172            0.655172
11       0.5                         0.837193           1.65517   1.65517            1                0.971109     1                           0.992902            0.172414        0.827586                   65.5172    65.5172            0.827586
12       0.604167                    0.247296           0.993103  1.54102            0.6              0.593313     0.931034                    0.924008            0.103448        0.931034                   -0.689655  54.1023            0.825771
13       0.6875                      0.0538957          0.413793  1.40439            0.25             0.109118     0.848485                    0.825233            0.0344828       0.965517                   -58.6207   40.4389            0.702359
14       0.791667                    0.000546562        0.331034  1.26316            0.2              0.0132943    0.763158                    0.718399            0.0344828       1                          -66.8966   26.3158            0.526316
15       0.895833                    0.000315971        0         1.11628            0                0.000354493  0.674419                    0.634906            0               1                          -100       11.6279            0.263158
16       1                           1.448e-05          0         1                  0                0.000138479  0.604167                    0.568784            0               1                          -100       0                  0
********************
Accuracy: [[0.7564214241030411, 0.9166666666666666]]
[INFO]  getting best model finished!, time elapsed: 441.3265037536621 seconds