D:\Workplace-Pycharm\.venv\Scripts\python.exe D:\Workplace-Pycharm\QuantitativeTransaction\SRC\sq\test\test_gm\for159869\sq_test3_3_3.py
2025-02-15 16:27:28.379765: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-15 16:27:29.433165: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
----------------------------------------
python sdk version: 3.0.168
c sdk version: 3.7.4
----------------------------------------
[INFO]  Start...
[INFO]  ForSZTrainer train...
[INFO]  Model name: GBM_grid_1_AutoML_1_20250215_160840_model_5
Checking whether there is an H2O instance running at http://localhost:54321..... not found.
Attempting to start a local H2O server...
; OpenJDK 64-Bit Server VM 18.9 (build 11.0.2+9, mixed mode)
  Starting server from D:\Workplace-Pycharm\.venv\Lib\site-packages\h2o\backend\bin\h2o.jar
  Ice root: C:\Users\Andy\AppData\Local\Temp\tmpmvoi9fk3
  JVM stdout: C:\Users\Andy\AppData\Local\Temp\tmpmvoi9fk3\h2o_Andy_started_from_python.out
  JVM stderr: C:\Users\Andy\AppData\Local\Temp\tmpmvoi9fk3\h2o_Andy_started_from_python.err
  Server is running at http://127.0.0.1:54321
Connecting to H2O server at http://127.0.0.1:54321 ... successful.
Warning: Your H2O cluster version is (7 months and 5 days) old.  There may be a newer version available.
Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html
--------------------------  -----------------------------
H2O_cluster_uptime:         02 secs
H2O_cluster_timezone:       Asia/Shanghai
H2O_data_parsing_timezone:  UTC
H2O_cluster_version:        3.46.0.4
H2O_cluster_version_age:    7 months and 5 days
H2O_cluster_name:           H2O_from_python_Andy_3tit9l
H2O_cluster_total_nodes:    1
H2O_cluster_free_memory:    3.844 Gb
H2O_cluster_total_cores:    16
H2O_cluster_allowed_cores:  16
H2O_cluster_status:         locked, healthy
H2O_connection_url:         http://127.0.0.1:54321
H2O_connection_proxy:       {"http": null, "https": null}
H2O_internal_security:      False
Python_version:             3.12.3 final
--------------------------  -----------------------------
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
response column levels:  [['0', '1']]
train shape: (779, 24)
test shape: (78, 24)
AutoML progress: |
16:28:01.162: AutoML: XGBoost is not available; skipping it.

███████████████████████████████████████████████████████████████| (done) 100%
********************
leaderboard:  model_id                                                      auc    logloss     aucpr    mean_per_class_error      rmse        mse
GBM_grid_1_AutoML_1_20250215_162801_model_5              0.993317   0.110603  0.992473               0.0489801  0.18977   0.0360128
StackedEnsemble_BestOfFamily_1_AutoML_1_20250215_162801  0.993108   0.105079  0.992353               0.0501763  0.186155  0.0346535
StackedEnsemble_AllModels_1_AutoML_1_20250215_162801     0.992492   0.109052  0.991712               0.0540166  0.19092   0.0364506
XRT_1_AutoML_1_20250215_162801                           0.992313   0.140131  0.991549               0.0525057  0.199496  0.0397987
GBM_grid_1_AutoML_1_20250215_162801_model_1              0.991643   0.118712  0.990644               0.0525057  0.194346  0.0377704
GBM_5_AutoML_1_20250215_162801                           0.991392   0.127022  0.990518               0.0516243  0.196718  0.0386982
GBM_4_AutoML_1_20250215_162801                           0.991186   0.125248  0.990215               0.0564719  0.198431  0.0393747
GBM_3_AutoML_1_20250215_162801                           0.9911     0.124839  0.98995                0.0571015  0.198927  0.0395718
DRF_1_AutoML_1_20250215_162801                           0.990938   0.141937  0.99005                0.0559683  0.202975  0.041199
GBM_2_AutoML_1_20250215_162801                           0.990825   0.129245  0.98974                0.0555276  0.200804  0.0403223
[22 rows x 7 columns]

********************
leaderboard.head:  model_id                                                      auc    logloss     aucpr    mean_per_class_error      rmse        mse
GBM_grid_1_AutoML_1_20250215_162801_model_5              0.993317   0.110603  0.992473               0.0489801  0.18977   0.0360128
StackedEnsemble_BestOfFamily_1_AutoML_1_20250215_162801  0.993108   0.105079  0.992353               0.0501763  0.186155  0.0346535
StackedEnsemble_AllModels_1_AutoML_1_20250215_162801     0.992492   0.109052  0.991712               0.0540166  0.19092   0.0364506
XRT_1_AutoML_1_20250215_162801                           0.992313   0.140131  0.991549               0.0525057  0.199496  0.0397987
GBM_grid_1_AutoML_1_20250215_162801_model_1              0.991643   0.118712  0.990644               0.0525057  0.194346  0.0377704
[5 rows x 7 columns]

********************
Best Model: Model Details
=============
H2OGradientBoostingEstimator : Gradient Boosting Machine
Model Key: GBM_grid_1_AutoML_1_20250215_162801_model_5


Model Summary:
    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves
--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------
    95                 95                          48256                  8            17           14.5474       26            39            35.8526

ModelMetricsBinomial: gbm
** Reported on train data. **

MSE: 0.0001674809552331783
RMSE: 0.01294144332109747
LogLoss: 0.006780565923859171
Mean Per-Class Error: 0.0
AUC: 1.0
AUCPR: 1.0
Gini: 1.0

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9089852824383164
       0    1    Error    Rate
-----  ---  ---  -------  -----------
0      418  0    0        (0.0/418.0)
1      0    361  0        (0.0/361.0)
Total  418  361  0        (0.0/779.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric                       threshold    value    idx
---------------------------  -----------  -------  -----
max f1                       0.908985     1        198
max f2                       0.908985     1        198
max f0point5                 0.908985     1        198
max accuracy                 0.908985     1        198
max precision                0.999947     1        0
max recall                   0.908985     1        198
max specificity              0.999947     1        0
max absolute_mcc             0.908985     1        198
max min_per_class_accuracy   0.908985     1        198
max mean_per_class_accuracy  0.908985     1        198
max tns                      0.999947     418      0
max fns                      0.999947     359      0
max fps                      5.48296e-05  418      399
max tps                      0.908985     361      198
max tnr                      0.999947     1        0
max fnr                      0.999947     0.99446  0
max fpr                      5.48296e-05  1        399
max tpr                      0.908985     1        198

Gains/Lift Table: Avg response rate: 46.34 %, avg score: 46.35 %
group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov
-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------
1        0.0102696                   0.999864           2.15789  2.15789            1                0.999924     1                           0.999924            0.0221607       0.0221607                  115.789  115.789            0.0221607
2        0.0205392                   0.999781           2.15789  2.15789            1                0.999825     1                           0.999874            0.0221607       0.0443213                  115.789  115.789            0.0443213
3        0.0308087                   0.999722           2.15789  2.15789            1                0.999761     1                           0.999837            0.0221607       0.066482                   115.789  115.789            0.066482
4        0.0410783                   0.999607           2.15789  2.15789            1                0.999674     1                           0.999796            0.0221607       0.0886427                  115.789  115.789            0.0886427
5        0.0513479                   0.99955            2.15789  2.15789            1                0.999567     1                           0.99975             0.0221607       0.110803                   115.789  115.789            0.110803
6        0.100128                    0.999064           2.15789  2.15789            1                0.99931      1                           0.999536            0.105263        0.216066                   115.789  115.789            0.216066
7        0.150193                    0.998549           2.15789  2.15789            1                0.99878      1                           0.999284            0.108033        0.3241                     115.789  115.789            0.3241
8        0.200257                    0.997805           2.15789  2.15789            1                0.998215     1                           0.999017            0.108033        0.432133                   115.789  115.789            0.432133
9        0.300385                    0.994852           2.15789  2.15789            1                0.996476     1                           0.99817             0.216066        0.648199                   115.789  115.789            0.648199
10       0.403081                    0.983897           2.15789  2.15789            1                0.991219     1                           0.996399            0.221607        0.869806                   115.789  115.789            0.869806
11       0.500642                    0.0235909          1.33449  1.99744            0.618421         0.615058     0.925641                    0.922086            0.130194        1                          33.4488  99.7436            0.930622
12       0.599487                    0.00507719         0        1.66809            0                0.0115493    0.773019                    0.771955            0               1                          -100     66.8094            0.746411
13       0.699615                    0.00271763         0        1.42936            0                0.00377622   0.662385                    0.662014            0               1                          -100     42.9358            0.559809
14       0.799743                    0.00148351         0        1.2504             0                0.00209382   0.579454                    0.579391            0               1                          -100     25.0401            0.373206
15       0.899872                    0.000666492        0        1.11127            0                0.00106604   0.514979                    0.515041            0               1                          -100     11.127             0.186603
16       1                           4.58488e-05        0        1                  0                0.000268592  0.463415                    0.463498            0               1                          -100     0                  0

ModelMetricsBinomial: gbm
** Reported on cross-validation data. **

MSE: 0.03601282460668595
RMSE: 0.18977045240681162
LogLoss: 0.11060259478886615
Mean Per-Class Error: 0.04898010576680936
AUC: 0.9933166774907554
AUCPR: 0.9924734222845307
Gini: 0.9866333549815107

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.21319360132901954
       0    1    Error    Rate
-----  ---  ---  -------  ------------
0      384  34   0.0813   (34.0/418.0)
1      6    355  0.0166   (6.0/361.0)
Total  390  389  0.0513   (40.0/779.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.213194     0.946667  226
max f2                       0.0576204    0.973046  248
max f0point5                 0.913425     0.966154  156
max accuracy                 0.52886      0.949936  194
max precision                0.999912     1         0
max recall                   0.0576204    1         248
max specificity              0.999912     1         0
max absolute_mcc             0.213194     0.899623  226
max min_per_class_accuracy   0.439302     0.942584  203
max mean_per_class_accuracy  0.213194     0.95102   226
max tns                      0.999912     418       0
max fns                      0.999912     359       0
max fps                      9.51833e-05  418       399
max tps                      0.0576204    361       248
max tnr                      0.999912     1         0
max fnr                      0.999912     0.99446   0
max fpr                      9.51833e-05  1         399
max tpr                      0.0576204    1         248

Gains/Lift Table: Avg response rate: 46.34 %, avg score: 46.13 %
group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov
-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------
1        0.0102696                   0.999816           2.15789   2.15789            1                0.99987      1                           0.99987             0.0221607       0.0221607                  115.789   115.789            0.0221607
2        0.0205392                   0.999707           2.15789   2.15789            1                0.999765     1                           0.999817            0.0221607       0.0443213                  115.789   115.789            0.0443213
3        0.0308087                   0.999579           2.15789   2.15789            1                0.999646     1                           0.99976             0.0221607       0.066482                   115.789   115.789            0.066482
4        0.0410783                   0.999464           2.15789   2.15789            1                0.999517     1                           0.999699            0.0221607       0.0886427                  115.789   115.789            0.0886427
5        0.0500642                   0.999312           2.15789   2.15789            1                0.999394     1                           0.999644            0.0193906       0.108033                   115.789   115.789            0.108033
6        0.100128                    0.998545           2.15789   2.15789            1                0.998922     1                           0.999283            0.108033        0.216066                   115.789   115.789            0.216066
7        0.150193                    0.997557           2.15789   2.15789            1                0.998117     1                           0.998895            0.108033        0.3241                     115.789   115.789            0.3241
8        0.200257                    0.996214           2.15789   2.15789            1                0.996966     1                           0.998412            0.108033        0.432133                   115.789   115.789            0.432133
9        0.300385                    0.986697           2.15789   2.15789            1                0.992484     1                           0.996436            0.216066        0.648199                   115.789   115.789            0.648199
10       0.400513                    0.936026           2.10256   2.14406            0.974359         0.972787     0.99359                     0.990524            0.210526        0.858726                   110.256   114.406            0.853941
11       0.500642                    0.210878           1.24494   1.96424            0.576923         0.576372     0.910256                    0.907694            0.124654        0.98338                    24.4939   96.4238            0.899647
12       0.599487                    0.0131256          0.168148  1.66809            0.0779221        0.0558806    0.773019                    0.767245            0.0166205       1                          -83.1852  66.8094            0.746411
13       0.699615                    0.00507375         0         1.42936            0                0.00803463   0.662385                    0.658587            0               1                          -100      42.9358            0.559809
14       0.799743                    0.00249466         0         1.2504             0                0.00362102   0.579454                    0.576585            0               1                          -100      25.0401            0.373206
15       0.899872                    0.000935246        0         1.11127            0                0.00159758   0.514979                    0.512606            0               1                          -100      11.127             0.186603
16       1                           9.518e-05          0         1                  0                0.000473012  0.463415                    0.461327            0               1                          -100      0                  0

Cross-Validation Metrics Summary:
                         mean         sd            cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid
-----------------------  -----------  ------------  ------------  ------------  ------------  ------------  ------------
accuracy                 0.96148884   0.01359866    0.96794873    0.9807692     0.94871795    0.94871795    0.9612903
aic                      nan          0.0           nan           nan           nan           nan           nan
auc                      0.9932113    0.0032170797  0.9953704     0.996992      0.988612      0.99209875    0.99298364
err                      0.038511164  0.01359866    0.032051284   0.01923077    0.051282052   0.051282052   0.038709678
err_count                6.0          2.1213202     5.0           3.0           8.0           8.0           6.0
f0point5                 0.951602     0.028808445   0.96153843    0.99085367    0.91939545    0.9273183     0.9589041
f1                       0.959727     0.012304353   0.9655172     0.97744364    0.9480519     0.94871795    0.9589041
f2                       0.96850115   0.0073820087  0.9695291     0.9643917     0.9785523     0.9711286     0.9589041
lift_top_group           2.1602116    0.08110054    2.1666667     2.2941177     2.1369863     2.08          2.1232877
loglikelihood            nan          0.0           nan           nan           nan           nan           nan
---                      ---          ---           ---           ---           ---           ---           ---
mcc                      0.9244177    0.025344923   0.93565744    0.9614415     0.90242374    0.9002469     0.92231876
mean_per_class_accuracy  0.961857     0.011605845   0.96825397    0.97794116    0.9518072     0.9501234     0.96115935
mean_per_class_error     0.03814296   0.011605845   0.031746034   0.022058824   0.04819277    0.049876545   0.03884063
mse                      0.0368456    0.007389866   0.032072835   0.027534418   0.046565272   0.040603746   0.03745172
pr_auc                   0.99244565   0.0035029985  0.9947923     0.99647516    0.9872917     0.99171174    0.9919574
precision                0.9465246    0.039694585   0.9589041     1.0           0.90123457    0.91358024    0.9589041
r2                       0.8517936    0.029153565   0.87094504    0.88802177    0.8129704     0.8373444     0.8496863
recall                   0.9747351    0.018661715   0.9722222     0.9558824     1.0           0.9866667     0.9589041
rmse                     0.19116838   0.019372834   0.1790889     0.16593498    0.21578988    0.20150371    0.19352446
specificity              0.948979     0.039864894   0.96428573    1.0           0.90361446    0.91358024    0.9634146
[22 rows x 8 columns]


Scoring History:
    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error
--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------
    2025-02-15 16:28:23  7.539 sec   0                  0.49866          0.690468            0.5             0.463415           1                0.536585
    2025-02-15 16:28:23  7.565 sec   5                  0.364146         0.448266            0.984128        0.98156            2.15789          0.0577664
    2025-02-15 16:28:23  7.588 sec   10                 0.282882         0.318893            0.993837        0.993424           2.15789          0.0359435
    2025-02-15 16:28:23  7.613 sec   15                 0.228795         0.237742            0.997972        0.997805           2.15789          0.0192555
    2025-02-15 16:28:23  7.642 sec   20                 0.187232         0.178999            0.999013        0.99891            2.15789          0.0141207
    2025-02-15 16:28:23  7.670 sec   25                 0.153702         0.136197            0.999735        0.999699           2.15789          0.00770218
    2025-02-15 16:28:23  7.697 sec   30                 0.129468         0.107267            0.999934        0.999924           2.15789          0.00385109
    2025-02-15 16:28:23  7.722 sec   35                 0.107505         0.0833883           0.999987        0.999985           2.15789          0.0012837
    2025-02-15 16:28:23  7.748 sec   40                 0.0906053        0.0660398           1               1                  2.15789          0
    2025-02-15 16:28:23  7.773 sec   45                 0.0749298        0.0518897           1               1                  2.15789          0
    2025-02-15 16:28:23  7.799 sec   50                 0.0625991        0.0415332           1               1                  2.15789          0
    2025-02-15 16:28:23  7.831 sec   55                 0.0528678        0.0336396           1               1                  2.15789          0
    2025-02-15 16:28:23  7.864 sec   60                 0.0446103        0.0273625           1               1                  2.15789          0
    2025-02-15 16:28:23  7.896 sec   65                 0.0373729        0.0222592           1               1                  2.15789          0
    2025-02-15 16:28:23  7.924 sec   70                 0.0306844        0.0179568           1               1                  2.15789          0
    2025-02-15 16:28:23  7.949 sec   75                 0.0258186        0.014708            1               1                  2.15789          0
    2025-02-15 16:28:23  7.981 sec   80                 0.0214376        0.0119315           1               1                  2.15789          0
    2025-02-15 16:28:23  8.013 sec   85                 0.0179419        0.0098105           1               1                  2.15789          0
    2025-02-15 16:28:23  8.041 sec   90                 0.0153356        0.00813954          1               1                  2.15789          0
    2025-02-15 16:28:23  8.070 sec   95                 0.0129414        0.00678057          1               1                  2.15789          0

Variable Importances:
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  --------------------
ma95        177.6856231689453      1.0                  0.18967362055411718
ma80        80.80123901367188      0.4547426942743996   0.08625269324355939
close       71.81746673583984      0.4041827664782708   0.07666280868351288
ma55        60.30046081542969      0.3393660091345454   0.06436877964555084
ma85        59.115928649902344     0.33269956001839446  0.06310433010545069
ma75        53.33843231201172      0.3001842881868782   0.056937040773865695
ma30        40.84554672241211      0.22987536072952702  0.04360129194575312
ma65        37.473594665527344     0.21089829327326648  0.04000184285382447
ma25        37.157752990722656     0.20912076243440744  0.03966469214397148
ma90        34.86555862426758      0.19622048200893016  0.0372178492495078
---         ---                    ---                  ---
ma5         33.173465728759766     0.1866975230585656   0.03541159514700391
ma70        30.428804397583008     0.17125079595579315  0.03248175849170966
ma35        29.63102149963379      0.1667609397495278   0.031630151209299934
ma20        27.36910629272461      0.1540310679311504   0.02921563033231847
ma10        24.977567672729492     0.14057168625837874  0.02666274068002414
ma15        21.31255531311035      0.11994529964220096  0.022750459251584712
ma50        16.468036651611328     0.09268074905505073  0.017579093228939045
ma3         14.081208229064941     0.07924787598418351  0.015031231559143758
ma45        9.481121063232422      0.05335896565034794  0.010120788203924268
ma40        9.01929759979248       0.05075986137165887  0.009627806685187614
[22 rows x 4 columns]

gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%
********************
predictions.head:    predict          p0           p1
        0  0.997833    0.0021666
        0  0.999089    0.000911153
        0  0.781356    0.218644
        1  0.0139576   0.986042
        0  0.394221    0.605779
        1  0.00552842  0.994472
        0  0.446805    0.553195
        0  0.99716     0.00284049
        0  0.178441    0.821559
        0  0.379321    0.620679
[10 rows x 3 columns]

********************
metrics: ModelMetricsBinomial: gbm
** Reported on test data. **

MSE: 0.041163441056778834
RMSE: 0.20288775482216476
LogLoss: 0.12213572018958213
Mean Per-Class Error: 0.029411764705882353
AUC: 0.9939839572192514
AUCPR: 0.9930464859174756
Gini: 0.9879679144385027

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8215588148357974
       0    1    Error    Rate
-----  ---  ---  -------  ----------
0      44   0    0        (0.0/44.0)
1      2    32   0.0588   (2.0/34.0)
Total  46   32   0.0256   (2.0/78.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.821559     0.969697  31
max f2                       0.0610143    0.965909  39
max f0point5                 0.821559     0.987654  31
max accuracy                 0.821559     0.974359  31
max precision                0.99993      1         0
max recall                   0.0610143    1         39
max specificity              0.99993      1         0
max absolute_mcc             0.821559     0.948818  31
max min_per_class_accuracy   0.821559     0.941176  31
max mean_per_class_accuracy  0.821559     0.970588  31
max tns                      0.99993      44        0
max fns                      0.99993      33        0
max fps                      0.000163032  44        77
max tps                      0.0610143    34        39
max tnr                      0.99993      1         0
max fnr                      0.99993      0.970588  0
max fpr                      0.000163032  1         77
max tpr                      0.0610143    1         39

Gains/Lift Table: Avg response rate: 43.59 %, avg score: 45.99 %
group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov
-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------
1        0.0128205                   0.999777           2.29412   2.29412            1                0.99993      1                           0.99993             0.0294118       0.0294118                  129.412   129.412            0.0294118
2        0.025641                    0.999492           2.29412   2.29412            1                0.999731     1                           0.999831            0.0294118       0.0588235                  129.412   129.412            0.0588235
3        0.0384615                   0.999286           2.29412   2.29412            1                0.999288     1                           0.99965             0.0294118       0.0882353                  129.412   129.412            0.0882353
4        0.0512821                   0.99928            2.29412   2.29412            1                0.999281     1                           0.999558            0.0294118       0.117647                   129.412   129.412            0.117647
5        0.0512821                   0.999271           0         2.29412            0                0            1                           0.999558            0               0.117647                   -100      129.412            0.117647
6        0.102564                    0.998669           2.29412   2.29412            1                0.999038     1                           0.999298            0.117647        0.235294                   129.412   129.412            0.235294
7        0.153846                    0.99784            2.29412   2.29412            1                0.998338     1                           0.998978            0.117647        0.352941                   129.412   129.412            0.352941
8        0.205128                    0.996929           2.29412   2.29412            1                0.997549     1                           0.998621            0.117647        0.470588                   129.412   129.412            0.470588
9        0.307692                    0.986263           2.29412   2.29412            1                0.992088     1                           0.996443            0.235294        0.705882                   129.412   129.412            0.705882
10       0.397436                    0.841014           2.29412   2.29412            1                0.971618     1                           0.990837            0.205882        0.911765                   129.412   129.412            0.911765
11       0.5                         0.139829           0.573529  1.94118            0.25             0.605628     0.846154                    0.91182             0.0588235       0.970588                   -42.6471  94.1176            0.834225
12       0.602564                    0.0108209          0.286765  1.65957            0.125            0.0271301    0.723404                    0.761235            0.0294118       1                          -71.3235  65.9574            0.704545
13       0.692308                    0.00492772         0         1.44444            0                0.00685115   0.62963                     0.663444            0               1                          -100      44.4444            0.545455
14       0.794872                    0.0022016          0         1.25806            0                0.00345834   0.548387                    0.578285            0               1                          -100      25.8065            0.363636
15       0.897436                    0.000890583        0         1.11429            0                0.00149633   0.485714                    0.512366            0               1                          -100      11.4286            0.181818
16       1                           0.000163032        0         1                  0                0.000473849  0.435897                    0.459864            0               1                          -100      0                  0
********************
Accuracy: [[0.8215588148357974, 0.9743589743589743]]
[INFO]  getting best model finished!, time elapsed: 394.4686369895935 seconds