D:\Workplace-Pycharm\.venv\Scripts\python.exe D:\Workplace-Pycharm\QuantitativeTransaction\SRC\sq\test\test_gm\for159869\sq_test3_3_3.py
2025-02-15 16:08:00.292791: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-15 16:08:01.413160: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
----------------------------------------
python sdk version: 3.0.168
c sdk version: 3.7.4
----------------------------------------
[INFO]  Start...
[INFO]  ForSZTrainer train...
[INFO]  Model name: Grid_GBM_py_3_sid_ad52_model_python_1724993029821_1_model_57
Checking whether there is an H2O instance running at http://localhost:54321..... not found.
Attempting to start a local H2O server...
; OpenJDK 64-Bit Server VM 18.9 (build 11.0.2+9, mixed mode)
  Starting server from D:\Workplace-Pycharm\.venv\Lib\site-packages\h2o\backend\bin\h2o.jar
  Ice root: C:\Users\Andy\AppData\Local\Temp\tmprxll9j3i
  JVM stdout: C:\Users\Andy\AppData\Local\Temp\tmprxll9j3i\h2o_Andy_started_from_python.out
  JVM stderr: C:\Users\Andy\AppData\Local\Temp\tmprxll9j3i\h2o_Andy_started_from_python.err
  Server is running at http://127.0.0.1:54321
Connecting to H2O server at http://127.0.0.1:54321 ... successful.
Warning: Your H2O cluster version is (7 months and 5 days) old.  There may be a newer version available.
Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html
--------------------------  -----------------------------
H2O_cluster_uptime:         03 secs
H2O_cluster_timezone:       Asia/Shanghai
H2O_data_parsing_timezone:  UTC
H2O_cluster_version:        3.46.0.4
H2O_cluster_version_age:    7 months and 5 days
H2O_cluster_name:           H2O_from_python_Andy_i5qzzo
H2O_cluster_total_nodes:    1
H2O_cluster_free_memory:    3.844 Gb
H2O_cluster_total_cores:    0
H2O_cluster_allowed_cores:  0
H2O_cluster_status:         locked, healthy
H2O_connection_url:         http://127.0.0.1:54321
H2O_connection_proxy:       {"http": null, "https": null}
H2O_internal_security:      False
Python_version:             3.12.3 final
--------------------------  -----------------------------
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
response column levels:  [['0', '1']]
train shape: (686, 24)
test shape: (171, 24)
AutoML progress: |
16:08:40.185: AutoML: XGBoost is not available; skipping it.

███████████████████████████████████████████████████████████████| (done) 100%
********************
leaderboard:  model_id                                                      auc    logloss     aucpr    mean_per_class_error      rmse        mse
GBM_grid_1_AutoML_1_20250215_160840_model_5              0.99128    0.120345  0.989563               0.0458054  0.189659  0.0359704
StackedEnsemble_BestOfFamily_1_AutoML_1_20250215_160840  0.990878   0.124743  0.98828                0.0471391  0.190142  0.0361538
GBM_5_AutoML_1_20250215_160840                           0.990767   0.128191  0.988832               0.0507596  0.195631  0.0382716
StackedEnsemble_AllModels_1_AutoML_1_20250215_160840     0.99031    0.125638  0.987109               0.0518709  0.193518  0.0374493
GBM_4_AutoML_1_20250215_160840                           0.989998   0.125958  0.986053               0.0500928  0.197343  0.0389444
GBM_grid_1_AutoML_1_20250215_160840_model_1              0.989194   0.133066  0.98594                0.0518923  0.200161  0.0400644
GBM_2_AutoML_1_20250215_160840                           0.989074   0.139759  0.986962               0.0570901  0.206089  0.0424726
GBM_3_AutoML_1_20250215_160840                           0.988856   0.136945  0.984911               0.0532473  0.205062  0.0420505
GBM_grid_1_AutoML_1_20250215_160840_model_2              0.988703   0.144312  0.985989               0.0527814  0.20548   0.0422221
DRF_1_AutoML_1_20250215_160840                           0.988151   0.157893  0.984848               0.0584451  0.211824  0.0448694
[22 rows x 7 columns]

********************
leaderboard.head:  model_id                                                      auc    logloss     aucpr    mean_per_class_error      rmse        mse
GBM_grid_1_AutoML_1_20250215_160840_model_5              0.99128    0.120345  0.989563               0.0458054  0.189659  0.0359704
StackedEnsemble_BestOfFamily_1_AutoML_1_20250215_160840  0.990878   0.124743  0.98828                0.0471391  0.190142  0.0361538
GBM_5_AutoML_1_20250215_160840                           0.990767   0.128191  0.988832               0.0507596  0.195631  0.0382716
StackedEnsemble_AllModels_1_AutoML_1_20250215_160840     0.99031    0.125638  0.987109               0.0518709  0.193518  0.0374493
GBM_4_AutoML_1_20250215_160840                           0.989998   0.125958  0.986053               0.0500928  0.197343  0.0389444
[5 rows x 7 columns]

********************
Best Model: Model Details
=============
H2OGradientBoostingEstimator : Gradient Boosting Machine
Model Key: GBM_grid_1_AutoML_1_20250215_160840_model_5


Model Summary:
    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves
--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------
    92                 92                          42664                  9            17           14.1304       22            35            32.337

ModelMetricsBinomial: gbm
** Reported on train data. **

MSE: 0.0002786141843975438
RMSE: 0.016691740005090654
LogLoss: 0.008836796087454036
Mean Per-Class Error: 0.0
AUC: 1.0
AUCPR: 1.0
Gini: 1.0

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9142741659176492
       0    1    Error    Rate
-----  ---  ---  -------  -----------
0      369  0    0        (0.0/369.0)
1      0    317  0        (0.0/317.0)
Total  369  317  0        (0.0/686.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.914274     1         195
max f2                       0.914274     1         195
max f0point5                 0.914274     1         195
max accuracy                 0.914274     1         195
max precision                0.999903     1         0
max recall                   0.914274     1         195
max specificity              0.999903     1         0
max absolute_mcc             0.914274     1         195
max min_per_class_accuracy   0.914274     1         195
max mean_per_class_accuracy  0.914274     1         195
max tns                      0.999903     369       0
max fns                      0.999903     315       0
max fps                      7.11308e-05  369       399
max tps                      0.914274     317       195
max tnr                      0.999903     1         0
max fnr                      0.999903     0.993691  0
max fpr                      7.11308e-05  1         399
max tpr                      0.914274     1         195

Gains/Lift Table: Avg response rate: 46.21 %, avg score: 46.21 %
group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov
-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------
1        0.0102041                   0.999821           2.16404  2.16404            1                0.999871     1                           0.999871            0.022082        0.022082                   116.404  116.404            0.022082
2        0.0204082                   0.999613           2.16404  2.16404            1                0.999711     1                           0.999791            0.022082        0.044164                   116.404  116.404            0.044164
3        0.0306122                   0.999521           2.16404  2.16404            1                0.999563     1                           0.999715            0.022082        0.0662461                  116.404  116.404            0.0662461
4        0.0408163                   0.999396           2.16404  2.16404            1                0.999457     1                           0.99965             0.022082        0.0883281                  116.404  116.404            0.0883281
5        0.0510204                   0.999291           2.16404  2.16404            1                0.999334     1                           0.999587            0.022082        0.11041                    116.404  116.404            0.11041
6        0.100583                    0.998701           2.16404  2.16404            1                0.999031     1                           0.999313            0.107256        0.217666                   116.404  116.404            0.217666
7        0.150146                    0.997678           2.16404  2.16404            1                0.998291     1                           0.998976            0.107256        0.324921                   116.404  116.404            0.324921
8        0.201166                    0.99689            2.16404  2.16404            1                0.99735      1                           0.998564            0.11041         0.435331                   116.404  116.404            0.435331
9        0.300292                    0.992419           2.16404  2.16404            1                0.994762     1                           0.997309            0.214511        0.649842                   116.404  116.404            0.649842
10       0.400875                    0.976863           2.16404  2.16404            1                0.987445     1                           0.994834            0.217666        0.867508                   116.404  116.404            0.867508
11       0.5                         0.0255012          1.33661  2                  0.617647         0.614467     0.924198                    0.919426            0.132492        1                          33.6612  100                0.929539
12       0.600583                    0.0078566          0        1.66505            0                0.0141095    0.769417                    0.767807            0               1                          -100     66.5049            0.742547
13       0.699708                    0.00379158         0        1.42917            0                0.00519575   0.660417                    0.659771            0               1                          -100     42.9167            0.558266
14       0.800292                    0.00219526         0        1.24954            0                0.00293259   0.577413                    0.577217            0               1                          -100     24.9545            0.371274
15       0.899417                    0.000961969        0        1.11183            0                0.00155336   0.513776                    0.513773            0               1                          -100     11.1831            0.186992
16       1                           6.6794e-05         0        1                  0                0.000432443  0.462099                    0.46214             0               1                          -100     0                  0

ModelMetricsBinomial: gbm
** Reported on cross-validation data. **

MSE: 0.03597036208070258
RMSE: 0.18965854075338284
LogLoss: 0.12034509453622444
Mean Per-Class Error: 0.04580544228155215
AUC: 0.991280038983355
AUCPR: 0.9895631286529414
Gini: 0.9825600779667101

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.39116963768801777
       0    1    Error    Rate
-----  ---  ---  -------  ------------
0      348  21   0.0569   (21.0/369.0)
1      11   306  0.0347   (11.0/317.0)
Total  359  327  0.0466   (32.0/686.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.39117      0.950311  211
max f2                       0.173048     0.963445  230
max f0point5                 0.827071     0.966184  168
max accuracy                 0.39117      0.953353  211
max precision                0.999897     1         0
max recall                   0.0320478    1         278
max specificity              0.999897     1         0
max absolute_mcc             0.39117      0.906763  211
max min_per_class_accuracy   0.406042     0.95122   204
max mean_per_class_accuracy  0.39117      0.954195  211
max tns                      0.999897     369       0
max fns                      0.999897     316       0
max fps                      0.000147668  369       399
max tps                      0.0320478    317       278
max tnr                      0.999897     1         0
max fnr                      0.999897     0.996845  0
max fpr                      0.000147668  1         399
max tpr                      0.0320478    1         278

Gains/Lift Table: Avg response rate: 46.21 %, avg score: 45.88 %
group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov
-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------
1        0.0102041                   0.999608           2.16404   2.16404            1                0.999772     1                           0.999772            0.022082        0.022082                   116.404   116.404            0.022082
2        0.0204082                   0.99945            2.16404   2.16404            1                0.999527     1                           0.99965             0.022082        0.044164                   116.404   116.404            0.044164
3        0.0306122                   0.999311           2.16404   2.16404            1                0.999382     1                           0.99956             0.022082        0.0662461                  116.404   116.404            0.0662461
4        0.0408163                   0.999094           2.16404   2.16404            1                0.999175     1                           0.999464            0.022082        0.0883281                  116.404   116.404            0.0883281
5        0.0510204                   0.998924           2.16404   2.16404            1                0.999026     1                           0.999376            0.022082        0.11041                    116.404   116.404            0.11041
6        0.100583                    0.997428           2.16404   2.16404            1                0.998266     1                           0.998829            0.107256        0.217666                   116.404   116.404            0.217666
7        0.150146                    0.995964           2.16404   2.16404            1                0.996747     1                           0.998142            0.107256        0.324921                   116.404   116.404            0.324921
8        0.201166                    0.992726           2.16404   2.16404            1                0.994239     1                           0.997152            0.11041         0.435331                   116.404   116.404            0.435331
9        0.300292                    0.980077           2.13221   2.15353            0.985294         0.988293     0.995146                    0.994228            0.211356        0.646688                   113.221   115.353            0.643978
10       0.400875                    0.891221           2.10131   2.14043            0.971014         0.952155     0.989091                    0.983672            0.211356        0.858044                   110.131   114.043            0.849914
11       0.5                         0.188982           1.17749   1.94953            0.544118         0.557756     0.900875                    0.899233            0.116719        0.974763                   17.7491   94.9527            0.882622
12       0.600583                    0.0234745          0.250903  1.66505            0.115942         0.0691848    0.769417                    0.76022             0.0252366       1                          -74.9097  66.5049            0.742547
13       0.699708                    0.00750655         0         1.42917            0                0.0133333    0.660417                    0.654411            0               1                          -100      42.9167            0.558266
14       0.800292                    0.00364095         0         1.24954            0                0.00548828   0.577413                    0.572853            0               1                          -100      24.9545            0.371274
15       0.899417                    0.00152332         0         1.11183            0                0.00245341   0.513776                    0.509989            0               1                          -100      11.1831            0.186992
16       1                           0.00013954         0         1                  0                0.000756117  0.462099                    0.458768            0               1                          -100      0                  0

Cross-Validation Metrics Summary:
                         mean         sd            cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid
-----------------------  -----------  ------------  ------------  ------------  ------------  ------------  ------------
accuracy                 0.9591558    0.012275704   0.9782609     0.96350366    0.9489051     0.95620435    0.9489051
aic                      nan          0.0           nan           nan           nan           nan           nan
auc                      0.99085873   0.0057000644  0.9968254     0.9952911     0.9867804     0.99206346    0.98333335
err                      0.040844176  0.012275704   0.02173913    0.03649635    0.05109489    0.04379562    0.05109489
err_count                5.6          1.67332       3.0           5.0           7.0           6.0           7.0
f0point5                 0.9540745    0.009704223   0.96330273    0.9651899     0.95166165    0.94427246    0.9459459
f1                       0.9558088    0.013730272   0.9767442     0.96062994    0.94736844    0.953125      0.9411765
f2                       0.9576785    0.021015272   0.990566      0.95611286    0.94311374    0.9621451     0.93645483
lift_top_group           2.1667628    0.08627923    2.1904762     2.140625      2.0447762     2.1746032     2.2833333
loglikelihood            nan          0.0           nan           nan           nan           nan           nan
---                      ---          ---           ---           ---           ---           ---           ---
mcc                      0.9180746    0.02517326    0.95726883    0.92672       0.8978243     0.9124401     0.8961197
mean_per_class_accuracy  0.95917416   0.013272335   0.98          0.96286386    0.9487207     0.9571        0.9471862
mean_per_class_error     0.04082587   0.013272335   0.02          0.03713613    0.051279318   0.042900044   0.052813854
mse                      0.036800303  0.011931535   0.021860292   0.02917966    0.05235493    0.037010957   0.04359567
pr_auc                   0.98865247   0.009051591   0.99620867    0.9948726     0.98714787    0.9913023     0.9737309
precision                0.9529918    0.010766033   0.95454544    0.96825397    0.95454544    0.93846154    0.9491525
r2                       0.85180676   0.047872726   0.9118926     0.8827755     0.7904798     0.85099554    0.8228902
recall                   0.95900214   0.026503185   1.0           0.953125      0.9402985     0.96825397    0.93333334
rmse                     0.18973258   0.031659335   0.14785226    0.17082055    0.22881201    0.19238232    0.20879577
specificity              0.9593461    0.009532186   0.96          0.9726027     0.95714283    0.9459459     0.96103895
[22 rows x 8 columns]


Scoring History:
    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error
--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------
    2025-02-15 16:09:00  6.154 sec   0                  0.498561         0.690271            0.5             0.462099           1                0.537901
    2025-02-15 16:09:00  6.176 sec   5                  0.371517         0.4598              0.97944         0.974307           2.16404          0.0568513
    2025-02-15 16:09:00  6.198 sec   10                 0.292641         0.332005            0.988651        0.985896           2.16404          0.0422741
    2025-02-15 16:09:00  6.221 sec   15                 0.235359         0.246375            0.995704        0.994127           2.16404          0.0262391
    2025-02-15 16:09:00  6.247 sec   20                 0.192            0.185308            0.998158        0.997676           2.16404          0.0145773
    2025-02-15 16:09:00  6.271 sec   25                 0.161936         0.144346            0.998829        0.99844            2.16404          0.00874636
    2025-02-15 16:09:00  6.294 sec   30                 0.133653         0.110936            0.999573        0.999462           2.16404          0.00291545
    2025-02-15 16:09:00  6.316 sec   35                 0.112849         0.0879512           0.999812        0.999774           2.16404          0.00145773
    2025-02-15 16:09:00  6.341 sec   40                 0.0951722        0.0700189           0.999906        0.999889           2.16404          0.00145773
    2025-02-15 16:09:00  6.364 sec   45                 0.0791912        0.0555661           1               1                  2.16404          0
    2025-02-15 16:09:00  6.392 sec   50                 0.0653506        0.0439825           1               1                  2.16404          0
    2025-02-15 16:09:00  6.415 sec   55                 0.0555753        0.0361822           1               1                  2.16404          0
    2025-02-15 16:09:00  6.438 sec   60                 0.0473538        0.0296291           1               1                  2.16404          0
    2025-02-15 16:09:00  6.463 sec   65                 0.0400835        0.0242753           1               1                  2.16404          0
    2025-02-15 16:09:01  6.487 sec   70                 0.0338702        0.0201298           1               1                  2.16404          0
    2025-02-15 16:09:01  6.511 sec   75                 0.0288882        0.0166722           1               1                  2.16404          0
    2025-02-15 16:09:01  6.535 sec   80                 0.0241424        0.0135197           1               1                  2.16404          0
    2025-02-15 16:09:01  6.559 sec   85                 0.0209708        0.0115332           1               1                  2.16404          0
    2025-02-15 16:09:01  6.583 sec   90                 0.0177251        0.00948053          1               1                  2.16404          0
    2025-02-15 16:09:01  6.595 sec   92                 0.0166917        0.0088368           1               1                  2.16404          0

Variable Importances:
variable    relative_importance    scaled_importance    percentage
----------  ---------------------  -------------------  --------------------
ma95        145.41180419921875     1.0                  0.17628682567792392
ma80        82.15733337402344      0.5649976893310897   0.09960164916753962
ma55        59.33234786987305      0.4080297895801214   0.07193027638711084
ma75        57.98160171508789      0.3987406801971267   0.07029272878060769
close       55.583099365234375     0.38224612968204275  0.06738495682931936
ma5         43.74739456176758      0.3008517417322755   0.053036198549657444
ma90        38.60092544555664      0.26545936664586156  0.046796989092471084
ma85        37.226192474365234     0.25600529942785233  0.045130361592862524
ma15        36.98792266845703      0.2543667130199582   0.04484150039641587
ma30        36.69985580444336      0.2523856712083938   0.044492268823919934
---         ---                    ---                  ---
ma65        28.04001235961914      0.1928317478352957   0.03399369671581015
ma70        23.723499298095703     0.16314699778838973  0.0287606663589985
ma100       22.178955078125        0.1525251350828378   0.026888171899850023
ma40        19.145444869995117     0.1316636223271479   0.023210562037309933
ma3         15.559649467468262     0.10700403280981957  0.018863401278779512
ma10        15.337054252624512     0.10547324089048689  0.018593542830546938
ma35        14.662280082702637     0.1008328048981144   0.017775495099690005
ma60        12.35186767578125      0.0849440507516075   0.014974517067225353
ma50        11.874180793762207     0.0816589881347886   0.014395403806353135
ma45        7.804538726806641      0.05367197504897317  0.009461662109248214
[22 rows x 4 columns]

gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%
********************
predictions.head:    predict        p0           p1
        0  0.999417  0.000583106
        0  0.998781  0.0012187
        0  0.99731   0.00269033
        0  0.998254  0.00174649
        0  0.993233  0.00676665
        0  0.992353  0.0076474
        0  0.228312  0.771688
        0  0.928234  0.0717655
        0  0.996995  0.00300518
        0  0.996846  0.00315371
[10 rows x 3 columns]

********************
metrics: ModelMetricsBinomial: gbm
** Reported on test data. **

MSE: 0.035535497716406114
RMSE: 0.18850861443553743
LogLoss: 0.1110072065178315
Mean Per-Class Error: 0.048180314309346564
AUC: 0.9928315412186379
AUCPR: 0.9917923804937993
Gini: 0.9856630824372759

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.7716882120823151
       0    1    Error    Rate
-----  ---  ---  -------  -----------
0      90   3    0.0323   (3.0/93.0)
1      5    73   0.0641   (5.0/78.0)
Total  95   76   0.0468   (8.0/171.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.771688     0.948052  74
max f2                       0.351352     0.975     86
max f0point5                 0.929073     0.968208  65
max accuracy                 0.781244     0.953216  72
max precision                0.999878     1         0
max recall                   0.351352     1         86
max specificity              0.999878     1         0
max absolute_mcc             0.781244     0.906332  72
max min_per_class_accuracy   0.771688     0.935897  74
max mean_per_class_accuracy  0.771688     0.95182   74
max tns                      0.999878     93        0
max fns                      0.999878     77        0
max fps                      6.32879e-05  93        169
max tps                      0.351352     78        86
max tnr                      0.999878     1         0
max fnr                      0.999878     0.987179  0
max fpr                      6.32879e-05  1         169
max tpr                      0.351352     1         86

Gains/Lift Table: Avg response rate: 45.61 %, avg score: 47.48 %
group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov
-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------
1        0.0116959                   0.999657           2.19231   2.19231            1                0.999828     1                           0.999828            0.025641        0.025641                   119.231   119.231            0.025641
2        0.0233918                   0.999392           2.19231   2.19231            1                0.999501     1                           0.999665            0.025641        0.0512821                  119.231   119.231            0.0512821
3        0.0350877                   0.99924            2.19231   2.19231            1                0.999316     1                           0.999548            0.025641        0.0769231                  119.231   119.231            0.0769231
4        0.0409357                   0.999094           2.19231   2.19231            1                0.999169     1                           0.999494            0.0128205       0.0897436                  119.231   119.231            0.0897436
5        0.0526316                   0.998859           2.19231   2.19231            1                0.998997     1                           0.999384            0.025641        0.115385                   119.231   119.231            0.115385
6        0.105263                    0.99796            2.19231   2.19231            1                0.998384     1                           0.998884            0.115385        0.230769                   119.231   119.231            0.230769
7        0.152047                    0.997037           2.19231   2.19231            1                0.997474     1                           0.99845             0.102564        0.333333                   119.231   119.231            0.333333
8        0.204678                    0.994285           2.19231   2.19231            1                0.995736     1                           0.997752            0.115385        0.448718                   119.231   119.231            0.448718
9        0.304094                    0.977783           2.19231   2.19231            1                0.989046     1                           0.994906            0.217949        0.666667                   119.231   119.231            0.666667
10       0.403509                    0.913513           2.06335   2.16054            0.941176         0.951961     0.985507                    0.984325            0.205128        0.871795                   106.335   116.054            0.861042
11       0.502924                    0.390565           1.16063   1.96288            0.529412         0.652772     0.895349                    0.918786            0.115385        0.987179                   16.0633   96.288             0.890405
12       0.602339                    0.020524           0.128959  1.66019            0.0588235        0.110017     0.757282                    0.7853              0.0128205       1                          -87.1041  66.0194            0.731183
13       0.701754                    0.00619327         0         1.425              0                0.0120754    0.65                        0.675759            0               1                          -100      42.5               0.548387
14       0.80117                     0.00263757         0         1.24818            0                0.00400153   0.569343                    0.592403            0               1                          -100      24.8175            0.365591
15       0.900585                    0.00114418         0         1.11039            0                0.00165741   0.506494                    0.52719             0               1                          -100      11.039             0.182796
16       1                           6.32879e-05        0         1                  0                0.000497374  0.45614                     0.474829            0               1                          -100      0                  0
********************
Accuracy: [[0.7812444171445294, 0.9532163742690059]]
[INFO]  getting best model finished!, time elapsed: 394.5506191253662 seconds